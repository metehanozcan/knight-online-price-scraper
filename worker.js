process.setMaxListeners(20);

const { Worker } = require('bullmq');
const { connection } = require('./queues/scrapeQueue');
const scrapingService = require('./services/scrapingService');
const cacheService = require('./services/cacheService');

console.log('ğŸš€ Worker baÅŸlatÄ±lÄ±yor...');

// Worker baÅŸlarken cache'den veri yÃ¼kle
(async () => {
  try {
    const cached = await cacheService.getPriceData();
    if (cached.data && Object.keys(cached.data).length > 0) {
      scrapingService.priceData = cached.data;
      scrapingService.lastUpdate = cached.lastUpdate;
      console.log(`âœ… Cache'den ${Object.keys(cached.data).length} site verisi yÃ¼klendi`);
    }
  } catch (err) {
    console.error('âŒ Cache yÃ¼kleme hatasÄ±:', err.message);
  }
})();

const worker = new Worker('scrape', async (job) => {
  console.log(`ğŸ”„ Scrape job baÅŸladÄ±: ${job.id}`);
  
  try {
    // Update flag'ini set et
    await cacheService.setUpdating(true);
    
    // Paralel scraping yap
    const data = await scrapingService.updateAllPrices();
    
    // Cache'e kaydet
    await cacheService.setPriceData({
      data,
      lastUpdate: new Date().toISOString(),
      isUpdating: false
    });
    
    console.log(`âœ… Scrape job tamamlandÄ±: ${job.id}`);
    return { success: true, sites: Object.keys(data).length };
    
  } catch (err) {
    console.error(`âŒ Scrape job baÅŸarÄ±sÄ±z: ${job.id}`, err.message);
    
    // Hata durumunda da update flag'ini kapat
    await cacheService.setUpdating(false);
    
    throw err;
  }
}, { 
  connection,
  concurrency: 1, // AynÄ± anda sadece 1 job Ã§alÄ±ÅŸsÄ±n
  removeOnComplete: { count: 10 },
  removeOnFail: { count: 20 }
});

worker.on('completed', (job) => {
  console.log(`âœ… Job ${job.id} baÅŸarÄ±yla tamamlandÄ±`);
});

worker.on('failed', (job, err) => {
  console.error(`âŒ Job ${job?.id} baÅŸarÄ±sÄ±z:`, err.message);
});

worker.on('error', err => {
  console.error('âŒ Worker hatasÄ±:', err);
});

console.log('âœ… Worker hazÄ±r ve dinliyor...');
